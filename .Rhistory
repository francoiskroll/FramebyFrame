if(endsWith(xlsnames[fi], '.xls') | endsWith(xlsnames[fi], '.XLS')) {
fif <- data.table::setkey( data.table::fread(paste0(ffDir, xlsnames[fi]), select=cols2take, fill=TRUE, integer64='numeric', colClasses=c(type='character')),
location, type) [.(locs, '101')]
# might be ok to change to integer64='integer64' here, but seems to make only a very slight different in memory
# fread(fi) = read that xls file and add it to the xli list
# setkey = set column 'location' as key (key is data.table concept, works a bit like row names so you can filter rows based on it)
# setkey = set column 'type' as second key
# [.(locs = filters on 'location' key, takes only location that are in locs (if box1: C001 >> C096; if box2: C097 >> C192)
# 101)] = filters on 'type' key, only takes = 101
# (v1: was excluding anything != 101, but subset by negation does not work as well)
# v11: found some rows where data1 says 'BACK_LIGHT' and location A01-1, A02-1, etc.
# this also shifts columns and type column stores well number
# which in consequence changes format of type column as character (as not only 71/101 anymore)
# (usual miserable Viewpoint formatting)
# i.e. indexing on the location column, [., (locs)] above, works ok; it takes only expected well numbers so will exclude rows A01-1
# the problem is indexing on the type column, it needs to know whether it looks through numbers (101, 71) or strings ('101', 'c1', ...)
# (clever) solution is to convert type column into character by default when important (see colClasses=c('location'))
# then filter to keep only '101', so whenever it is 'c1' (when BACK_LIGHT rows appear), it will get thrown out
### OPTION 2: if we have a .xlsx, we need to use read_xlsx (fread does not like .xlsx)
# note it is faster than openxlsx's read.xlsx (source: StackOverflow)
} else if (endsWith(xlsnames[fi], '.xlsx')) {
# import the file, only columns we need
fif <- data.table::data.table( readxl::read_xlsx(paste0(ffDir, xlsnames[fi]),
range=readxl::cell_cols(cols2take), # **
col_types='text', # ***
progress=FALSE) )
# ** ideally we only want to import the few columns we need, but readxl only imports the range of columns (e.g. if given 1, 3; it will import 1, *2*, 3)
# at least we skip all the empty data columns, which saves time vs importing the entire file
# but we need to select again
fif <- fif %>%
select(all_of(cols2take)) %>%
subset(type=='101')
# *** why do we set every column to character?
# it is delete any row that is not type 101
# there are some BACK_LIGHT rows, which we want to throw away
# in these rows, the columns get shifted so type now has location info, e.g. c1 or LocA22
# subset for type = 101 does not work because it expects all numeric but sees e.g. "LocA22"
# so convert the whole column to character, and keep only "101" (see subset above)
# unfortunately, it means we now have to convert back some columns
fif$abstime <- as.numeric(fif$abstime)
fif$time <- as.numeric(fif$time)
fif$data1 <- as.numeric(fif$data1)
### if anything else than xlsx or xls or XLS: ERROR!
} else {
stop('\t \t \t \t >>> Error vpSorter: file', xlsnames[fi], 'does not end with .xls or .XLS or .xlsx. \n')
}
fif$time <- fif$time/timeconv
# times used to be in seconds (old VP system), now in microseconds
# convert back in seconds, easier to read and Vp_Extract.m expects it to calculate frame rate (fps)
# v1: was dividing all columns on big dataframe with all of data, which was hard on memory
# v2: now doing it file by file
# take from this file all the data of well w and put the values in slot w of the list
lapply(1:length(locs), function(w) {  # pw = per well
pw[[w]][[fi]] <<- fif[location==locs[w], c('abstime', 'time', 'data1')]
})
# keep track of how many rows of data we are importing
rowcount <<- rowcount + nrow(fif)
})
rowcount
pw <- lapply(1:length(pw), function(w){
SpeaknRecord('Binding data from well #', w, 'of', length(pw))
data.table::rbindlist(pw[[w]])})
sum(unlist(lapply(pw, function(x) {nrow(x)})))
rowcount
# total number of rows (splitted in different wells in pw) should be same as total number of rows in xls files
if(!identical(rowcount, sum(unlist(lapply(pw, function(x) {nrow(x)})))))
stop('\t \t \t \t >>> Error: Something wrong when appending all the xls files together... \n')
devtools::load_all(".")
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=TRUE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
pq
pw
pw <- vector(mode='list',length=length(locs)) # pre-allocate list of 96 elements (one per well)
ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/'
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx'
boxGen=2
twoBoxMode=TRUE
boxnum=1
zt0='09:00:00'
date0=NA
time0=NA
dayduration=14
exportXlsOrNo=FALSE
#### check settings make sense ####
# vpSorter takes a while to run so need to be thorough so we do not throw an error after the user waited for an hour
# about start of the experiment,
# not giving enough information:
if (is.na(zebpath)) {
if(is.na(date0)) stop('\t \t \t \t >>> Error vpSorter: if not giving zebpath, you will need to enter manually date0 as DD/MM/YYYY, e.g. date0="28/01/2021" \n')
if(is.na(time0)) stop('\t \t \t \t >>> Error vpSorter: if not giving zebpath, you will need to enter manually time0 as HH:MM:SS, e.g. time0="10:27:35" \n')
}
# giving too much information:
if (!is.na(date0) & !is.na(time0)) {
if(!is.na(zebpath)) {
message('\t \t \t \t Warning vpSorter: you should not give date0 and time0 if you have a Zebralab XLS file to be used as source for start date/time. Will trust what the Zebralab XLS file says. \n')
date0 <- NA
time0 <- NA
}
}
# boxGen is 1 or 2
if (! boxGen %in% c(1, 2)) stop('\t \t \t \t Error vpSorter: boxGen can only be 1 or 2, e.g. boxGen=2 \n')
# twoBoxMode is logical
if (!is.logical(twoBoxMode)) stop('\t \t \t \t Error vpSorter: twoBoxMode can only be TRUE or FALSE, e.g. twoBoxMode=TRUE \n')
# give zt0
if (!is.character(zt0)) stop('\t \t \t \t Error vpSorter: something wrong about zt0 setting, give e.g. zt0="09:00:00" for 9 AM \n')
# dayduration cannot be above 24
if (!is.numeric(dayduration) | dayduration > 24)
stop('\t \t \t \t Error vpSorter: something wrong about dayduration setting, give a number below 24, e.g. dayduration=14 \n')
# exportXlsOrNo is logical
if (!is.logical(exportXlsOrNo)) stop('\t \t \t \t Error vpSorter: exportXlsOrNo can only be TRUE or FALSE, e.g. exportXlsOrNo=FALSE \n')
# ffDir: on Windows, pressing Tab key automatically writes the directory as ".../" but we need it to finish by "\\" or "\\\\"
# function whatSlash in pathUtilities was written for this situation
# if the last character is / and we are on Windows, replace by \\\\:
if(substrEnding(ffDir, 1)=='/') {
ffDir <- paste0( paste0(strsplit(ffDir, '')[[1]][1:(nchar(ffDir)-1)], collapse='') , whatSlash(ffDir))
# if on Mac: will replace by / by /, i.e. no change
# if on Windows: will replace by / by \\\\
# also, if there is no slash at the end, add one. That will avoid another error
} else if(! substrEnding(ffDir, 1) %in% c('/', '\\')) { # \\ is actually \, first \ is escape
ffDir <- paste0( paste0(strsplit(ffDir, '')[[1]][1:nchar(ffDir)], collapse='') , whatSlash(ffDir))
# if on Mac: will add /
# if on Windows: will add \\\\
}
#### folder with xls files ####
# ask user where the folder with all the xls files is
cat('\t \t \t \t >>> Sorting RAW .xls files in directory', ffDir, '\n')
# prepare export paths
# folder name alone is:
fdir <- levelUpPath(ffDir, upn=1, slash=whatSlash(ffDir))
# find date_box:
if (boxnum==1){
dtbx <- substr(fdir, 1, 9) # date box for box1, eg. 210218_11
} else if (boxnum==2){
dtbx <- paste(substr(fdir, 1, 6), # date box for box2, eg. 210218_11
substr(fdir, 11, 12), sep='_')
} else {
stop('\t \t \t \t >>> Box number can only be 1 or 2. Did you write something else? \n')
}
SpeaknRecord('EXPERIMENT', dtbx, header=1)
expfolder <-  parentFolder(ffDir, upn=1, slash=whatSlash(ffDir))
#### open first xls file to check formatting ###
SpeaknRecord('FORMATTING CHECK', header=3)
# let us start by opening the first xls file to check the formatting
# important as Viewpoint is never consistent with the formatting between systems
# below only supports differences I have seen, unfortunately it would likely not support a format I have never seen
xlsnames <- list.files(path=ffDir) # get the names of all the xls to read
# edit 12/04/2022 -- used to be okay without naturalsort but now does not import in the right order (it goes file 1, 10, ... instead of file 1, 2, ...), so
xlsnames <- naturalsort::naturalsort(xlsnames)
# quick check: we should not have anything else than .xls or .XLS files in there -- check this
# if( !all(substrEnding(xlsnames, 4)=='.xls') & !all(substrEnding(xlsnames, 4)=='.XLS') )
#   stop('\t \t \t \t >>> Error: there is something else than just .xls files in this folder, check and run again \n')
# if( !all(substrEnding(xlsnames, 4)=='.xls') & !all(substrEnding(xlsnames, 4)=='.XLS') &  !all(substrEnding(xlsnames, 5)=='.xlsx'))
#   stop('\t \t \t \t >>> Error: there is something else than just .xls files in this folder, check and run again \n')
if( !all(endsWith(xlsnames, '.xls')) & !all(endsWith(xlsnames, '.XLS')) &  !all(endsWith(xlsnames, '.xlsx')) )
stop('\t \t \t \t >>> Error: there is something else than just .xls/.XLS/.xlsx files in this folder, check and run again \n')
# if a file is opened in Excel, there might be some hidden files like ~$230106_....xlsx
# make sure we do not try to import those
xlsnames <- xlsnames[!startsWith(xlsnames, '~$')]
# import the first xls file
# fi1 <- read.table(paste0(ffDir, xlsnames[1]), fill=TRUE, header=TRUE)
## tmp 10/02/2023
fi1 <- readxl::read_xlsx(paste0(ffDir, xlsnames[1]), progress=FALSE)
##
# 1- column abstime
colabstime <- which(colnames(fi1)=='abstime')
if(length(colabstime)==0)
stop('\t \t \t \t >>> Error: could not find column abstime \n')
SpeaknRecord('Selecting column abstime at position', colabstime)
# 2- column time
coltime <- which(colnames(fi1)=='time')
if(length(coltime)==0)
stop('\t \t \t \t >>> Error: could not find column time \n')
SpeaknRecord('Selecting column time at position', coltime)
# 3- column type
coltype <- which(colnames(fi1)=='type')
if(length(coltype)==0)
stop('\t \t \t \t >>> Error: could not find column type \n')
SpeaknRecord('Selecting column type at position', coltype)
# 4- column location
collocation <- which(colnames(fi1)=='location')
if(length(collocation)==0)
stop('\t \t \t \t >>> Error: could not find column location \n')
SpeaknRecord('Selecting column location at position', collocation)
# 5- column data1
coldata1 <- which(colnames(fi1)=='data1')
if(length(coldata1)==0)
stop('\t \t \t \t >>> Error: could not find column data1 \n')
SpeaknRecord('Selecting column data1 at position', coldata1)
# the indices of the columns we want:
cols2take <- c(colabstime, coltime, coltype, collocation, coldata1)
### how is location column formatted? ###
# options I have seen:
# option1: C001--C192
# option2: c1--c192
# option3: w001--w192
# what is the first character?
locfirstchar <- strsplit(fi1$location[1], '')[[1]][1]
# how many characters?
# minimum number of characters will allow us to differentiate option1 and option2
# as if option1: always 4, if option2: between 2 and 4
locnchar <- min(nchar(fi1$location))
# how many wells in each box?
# can tell by number of unique well IDs, then divide by 2 as we get well IDs of box1 and box2 wells together
# ! if given data for only one box, this will be wrong
# there is no simple way to guess whether we are given data for a single box or two from the raw .xls files alone
# for example, we could confuse two 48-well plates with a single box with a 96-well plate
# hence, asked user at the top whether 'twoBoxMode'; if yes, then divide number of unique well IDs by two
nwells <- length(sort(unique(readr::parse_number(fi1$location))))
if (twoBoxMode) {
nwells <- nwells/2
}
SpeaknRecord('Detected *', nwells, '* - well plate')
# additionally, note Zebralab starts second box at well 97 regardless of number of wells
# differentiate between various options:
if (locfirstchar=='C' & locnchar==4) { # OPTION 1
SpeaknRecord('Locations are written CXXX, e.g. C096')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting C001, C002, ...')
locs=sprintf('C%0.3d', 1:nwells) # Box1 locations = C001 >> C096 if 96 wells, or C001 >> C024 if 24 wells, etc.
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting C097, C098, ...')
locs=sprintf('C%0.3d', 97:(97+nwells-1)) # Box2 locations = C097 >> C192 if 96 wells, or C097 >> C120 if 24 wells, etc.
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='c' & locnchar==2) { # OPTION 2
SpeaknRecord('Locations are written c..., e.g. c96')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting c1, c2, ...')
locs=sprintf('c%i', 1:nwells) # Box1 locations = c1 >> c96
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting c97, c98, ...')
locs=sprintf('c%i', 97:(97+nwells-1)) # Box2 locations = c97 >> c192
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='w' & locnchar==4) { # OPTION 3
SpeaknRecord('Locations are written w..., e.g. w096')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting w001, w002, ...')
locs=sprintf('w%0.3d', 1:nwells) # Box1 locations = w001 >> w096
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting w097, w098, ...')
locs=sprintf('w%0.3d', 97:(97+nwells-1)) # Box2 locations = w097 >> w192
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='L' & locnchar==6) { # OPTION 4
SpeaknRecord('Locations are written LocA/B..., e.g. LocA96')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting LocA01, LocA02, ...')
locs=sprintf('LocA%0.2d', 1:nwells) # Box1 locations = LocA01 >> LocA96
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting LocB01, LocB02...')
# note 12/01/2023, I am guessing this, only time I have seen the Loc version of the column it was for a single box and it was LocA01, ..., LocA96
# so probably second box would be LocB01?
locs=sprintf('LocB%0.2d', 1:nwells) # Box2 locations = LocB01 >> LocB96
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else {
stop('\t \t \t \t >>> Error: in the xls files, expecting the location column to be formatted as: C001 or c1 or w001.
\t \t \t Open one of the xls files, is your location column written differently? Viewpoint always finds new ways to name the wells!
\t \t \t Send me a sample xls file on francois@kroll.be and I will update the package. \n')
}
# note, in comments below will usually assume 96 wells but now locs created above actually represents number of wells
# i.e. not always 96
### what is the time unit? ###
# Viewpoint is not consistent, sometimes seconds sometimes microseconds (?)
unitcheck <- min(fi1$time[which(fi1$time!=0)]) # in first file, what is the smallest value that is not 0?
# if microseconds and fps ~ 25, should be ~ 40000
# will leave large margin to allow from 10 fps (~ 100,000) up to 50 fps (~ 20,000)
if (unitcheck > 18000 & unitcheck < 102000) {
SpeaknRecord('Time column seems to be in microseconds, will divide by 1M to convert into seconds')
timeconv <- 1000000 # i.e. we need to divide by 1M to get seconds
# if seconds and fps ~ 25, should be ~ 0.04
# will leave large margin to allow from 10 fps (~ 0.1) up to 50 fps (~ 0.02)
} else if (unitcheck > 0.01 & unitcheck < 0.11) {
SpeaknRecord('Time column seems to be in seconds, no conversion needed')
timeconv <- 1 # i.e. we already have seconds (divide by 1 does not do anything)
} else {
stop('\t \t \t \t >>> Did not recognise time unit \n')
}
# we do not need fi1 anymore, delete it
rm(fi1)
#### import and append all the xls files ####
# notes below likely to be important only for very long 200+ hours, but will keep advice if needed for future
# memory intensive step ahead, default R/Windows/Mac settings will throw errors
# on Windows (common Rihel lab computer: i7 4-core + 16 Gb RAM + 2 drives, C: = SSD 236Gb & D: = HDD 1.81Tb)
# current settings that seem to work:
# 1- increase memory in R settings file
# open Notepad as administrator
# File > Open..., file C: / Program Files / R / R-xxx / etc / Rprofile.site (bottom right, All files if you cannot see it)
# add line:
# invisible(utils::memory.limit(128000))
# close R and start again, can run memory.limit() in Console to check it is reading it correctly
# ! if multiple versions of R co-existing, make sure you change the Rprofile.site of the correct one (folder name xxx above should be different)
# 2- increase allowed size of page file
# (from what I understand this is to allow more virtual RAM,
# i.e. actually being written on the disk but treated as RAM by computer)
# Control Panel >> System and Security >> System >> Change Settings (right) >> Advanced tab >> Performance: Settings...
# >> Virtual Memory: Change...
# unticked Automatically...
# for both D: drive & C: drive, tick Custom size, Initial size = 16 / Maximum size = 64000
# Set, then restart computer
tictoc::tic()
pw <- vector(mode='list',length=length(locs)) # pre-allocate list of 96 elements (one per well)
pw <- lapply(pw, function(w){
vector(mode='list', length=length(xlsnames)) # in each of these 96 elements, pre-allocate a list of number of files elements
})
rowcount <- as.integer(0) # total number of rows, will use it to check everything makes sense after
SpeaknRecord('DATA IMPORT', header=3)
lapply(1:length(xlsnames), function(fi) { # fi for file index; xli for list of xls
SpeaknRecord('Importing file #', fi, 'of', length(xlsnames))
# there are two options to import each file:
### OPTION 1: if we have a .xls or .XLS we can use fread, which will speed things up
if(endsWith(xlsnames[fi], '.xls') | endsWith(xlsnames[fi], '.XLS')) {
fif <- data.table::setkey( data.table::fread(paste0(ffDir, xlsnames[fi]), select=cols2take, fill=TRUE, integer64='numeric', colClasses=c(type='character')),
location, type) [.(locs, '101')]
# might be ok to change to integer64='integer64' here, but seems to make only a very slight different in memory
# fread(fi) = read that xls file and add it to the xli list
# setkey = set column 'location' as key (key is data.table concept, works a bit like row names so you can filter rows based on it)
# setkey = set column 'type' as second key
# [.(locs = filters on 'location' key, takes only location that are in locs (if box1: C001 >> C096; if box2: C097 >> C192)
# 101)] = filters on 'type' key, only takes = 101
# (v1: was excluding anything != 101, but subset by negation does not work as well)
# v11: found some rows where data1 says 'BACK_LIGHT' and location A01-1, A02-1, etc.
# this also shifts columns and type column stores well number
# which in consequence changes format of type column as character (as not only 71/101 anymore)
# (usual miserable Viewpoint formatting)
# i.e. indexing on the location column, [., (locs)] above, works ok; it takes only expected well numbers so will exclude rows A01-1
# the problem is indexing on the type column, it needs to know whether it looks through numbers (101, 71) or strings ('101', 'c1', ...)
# (clever) solution is to convert type column into character by default when important (see colClasses=c('location'))
# then filter to keep only '101', so whenever it is 'c1' (when BACK_LIGHT rows appear), it will get thrown out
### OPTION 2: if we have a .xlsx, we need to use read_xlsx (fread does not like .xlsx)
# note it is faster than openxlsx's read.xlsx (source: StackOverflow)
} else if (endsWith(xlsnames[fi], '.xlsx')) {
# import the file, only columns we need
fif <- data.table::data.table( readxl::read_xlsx(paste0(ffDir, xlsnames[fi]),
range=readxl::cell_cols(cols2take), # **
col_types='text', # ***
progress=FALSE) )
# ** ideally we only want to import the few columns we need, but readxl only imports the range of columns (e.g. if given 1, 3; it will import 1, *2*, 3)
# at least we skip all the empty data columns, which saves time vs importing the entire file
# but we need to select again
fif <- fif %>%
select(all_of(cols2take)) %>%
subset(type=='101')
# *** why do we set every column to character?
# it is delete any row that is not type 101
# there are some BACK_LIGHT rows, which we want to throw away
# in these rows, the columns get shifted so type now has location info, e.g. c1 or LocA22
# subset for type = 101 does not work because it expects all numeric but sees e.g. "LocA22"
# so convert the whole column to character, and keep only "101" (see subset above)
# unfortunately, it means we now have to convert back some columns
fif$abstime <- as.numeric(fif$abstime)
fif$time <- as.numeric(fif$time)
fif$data1 <- as.numeric(fif$data1)
### if anything else than xlsx or xls or XLS: ERROR!
} else {
stop('\t \t \t \t >>> Error vpSorter: file', xlsnames[fi], 'does not end with .xls or .XLS or .xlsx. \n')
}
fif$time <- fif$time/timeconv
# times used to be in seconds (old VP system), now in microseconds
# convert back in seconds, easier to read and Vp_Extract.m expects it to calculate frame rate (fps)
# v1: was dividing all columns on big dataframe with all of data, which was hard on memory
# v2: now doing it file by file
# take from this file all the data of well w and put the values in slot w of the list
lapply(1:length(locs), function(w) {  # pw = per well
pw[[w]][[fi]] <<- fif[location==locs[w], c('abstime', 'time', 'data1')]
})
# keep track of how many rows of data we are importing
rowcount <<- rowcount + nrow(fif)
})
rowcount
pw
locs
# differentiate between various options:
if (locfirstchar=='C' & locnchar==4) { # OPTION 1
SpeaknRecord('Locations are written CXXX, e.g. C096')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting C001, C002, ...')
locs=sprintf('C%0.3d', 1:nwells) # Box1 locations = C001 >> C096 if 96 wells, or C001 >> C024 if 24 wells, etc.
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting C097, C098, ...')
locs=sprintf('C%0.3d', 97:(97+nwells-1)) # Box2 locations = C097 >> C192 if 96 wells, or C097 >> C120 if 24 wells, etc.
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='c' & locnchar==2) { # OPTION 2
SpeaknRecord('Locations are written c..., e.g. c96')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting c1, c2, ...')
locs=sprintf('c%i', 1:nwells) # Box1 locations = c1 >> c96
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting c97, c98, ...')
locs=sprintf('c%i', 97:(97+nwells-1)) # Box2 locations = c97 >> c192
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='w' & locnchar==4) { # OPTION 3
SpeaknRecord('Locations are written w..., e.g. w096')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting w001, w002, ...')
locs=sprintf('w%0.3d', 1:nwells) # Box1 locations = w001 >> w096
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting w097, w098, ...')
locs=sprintf('w%0.3d', 97:(97+nwells-1)) # Box2 locations = w097 >> w192
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else if (locfirstchar=='L' & locnchar==6) { # OPTION 4
SpeaknRecord('Locations are written LocA/B..., e.g. LocA96')
# set the locations accordingly
if (boxnum==1){
SpeaknRecord('Running BOX1 so expecting LocA01, LocA02, ...')
locs=sprintf('LocA%0.2d', 1:nwells) # Box1 locations = LocA01 >> LocA96
} else if (boxnum==2) {
SpeaknRecord('Running BOX2 so expecting LocB01, LocB02...')
# note 12/01/2023, I am guessing this, only time I have seen the Loc version of the column it was for a single box and it was LocA01, ..., LocA96
# so probably second box would be LocB01?
locs=sprintf('LocB%0.2d', 1:nwells) # Box2 locations = LocB01 >> LocB96
} else {
stop('\t \t \t \t >>> Error: Box number can only be 1 or 2. Did you write something else? \n')
}
} else {
stop('\t \t \t \t >>> Error: in the xls files, expecting the location column to be formatted as: C001 or c1 or w001.
\t \t \t Open one of the xls files, is your location column written differently? Viewpoint always finds new ways to name the wells!
\t \t \t Send me a sample xls file on francois@kroll.be and I will update the package. \n')
}
locs
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
199475
199475/25
199475/25/60
199475/25/60/60
devtools::load_all(".")
# still ok with .xls files?
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/010622_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
devtools::load_all(".")
# still ok with .xls files?
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/010622_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
devtools::load_all(".")
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
date0=NA,
time0=NA,
dayduration=14,
exportXlsOrNo=FALSE)
vpSorter(ffDir='~/Dropbox/phd/leahUpdateVpSorter/v2/230106_LDtest_rawoutput/',
zebpath='~/Dropbox/phd/leahUpdateVpSorter/230106_LDtest.xlsx',
boxGen=2,
twoBoxMode=FALSE,
boxnum=1,
zt0='09:00:00',
dayduration=14)
